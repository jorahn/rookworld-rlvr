"""
Chess Environment Utility for RookWorld GRPO Training

This module provides chess state management utilities for generating ground truth
for the Environment (A:) task. It is NOT a separate model wrapper, but a utility
for creating expected outputs and validating model predictions.

Key insights:
- A: task requires structured environment responses
- Ground truth is generated by applying UCI moves to board states
- Validation compares model predictions against actual chess rules
"""

from typing import Dict, Any, List, Optional, Tuple
import chess
import chess.engine
from dataclasses import dataclass


@dataclass
class EnvironmentResponse:
    """Structured response for A: task"""
    previous_fen: str
    uci_move: str
    move_history: str  # Recent moves for context
    new_fen: str
    reward: float
    terminated: bool
    truncated: bool
    
    def to_structured_string(self) -> str:
        """Convert to A: format string"""
        return (f"{self.previous_fen}+{self.uci_move}+{self.move_history}+"
                f"{self.new_fen}+{self.reward}+{int(self.terminated)}+{int(self.truncated)}")


class ChessEnvironment:
    """
    Chess environment utility for A: task ground truth generation
    
    This is NOT a model wrapper - it's a utility for:
    1. Applying UCI moves to board states
    2. Generating expected A: task outputs  
    3. Validating model predictions against chess rules
    """
    
    def __init__(self, default_reward: float = 0.001):
        """
        Initialize chess environment utility
        
        Args:
            default_reward: Standard reward value for valid moves (matches RookWorld)
        """
        self.default_reward = default_reward
    
    def apply_move(
        self, 
        fen: str, 
        uci_move: str, 
        move_history: str = "",
        max_moves_for_termination: int = 150
    ) -> EnvironmentResponse:
        """
        Apply UCI move to board and generate expected A: task response
        
        Args:
            fen: Current board position in FEN notation
            uci_move: UCI move to apply (e.g., "e2e4")
            move_history: Recent moves for context (e.g., "e2e4 e7e5")
            max_moves_for_termination: Maximum moves before declaring truncation
            
        Returns:
            EnvironmentResponse with all required fields
        """
        try:
            # Create board from FEN
            board = chess.Board(fen)
            
            # Parse and validate move
            move = chess.Move.from_uci(uci_move)
            if move not in board.legal_moves:
                raise ValueError(f"Illegal move: {uci_move} in position {fen}")
            
            # Apply move
            board.push(move)
            
            # Generate response
            response = EnvironmentResponse(
                previous_fen=fen,
                uci_move=uci_move,
                move_history=move_history,
                new_fen=board.fen(),
                reward=self.default_reward,
                terminated=board.is_game_over(),
                truncated=board.fullmove_number >= max_moves_for_termination
            )
            
            return response
            
        except (ValueError, chess.IllegalMoveError) as e:
            raise ValueError(f"Failed to apply move {uci_move} to position {fen}: {e}")
    
    def validate_prediction(
        self, 
        predicted_text: str, 
        expected_response: EnvironmentResponse
    ) -> Dict[str, Any]:
        """
        Validate model's A: task prediction against expected response
        
        Args:
            predicted_text: Model's generated text (should be A: format)
            expected_response: Ground truth environment response
            
        Returns:
            Dictionary with validation results:
                - is_valid_format: bool
                - parsed_response: EnvironmentResponse or None
                - fen_exact_match: bool  
                - fen_similarity_score: float (0.0 to 1.0)
                - reward_accuracy: float (0.0 to 1.0)
                - flag_accuracy: float (0.0 to 1.0)
        """
        try:
            parsed = self.parse_prediction(predicted_text)
            
            if parsed is None:
                return {
                    "is_valid_format": False,
                    "parsed_response": None,
                    "fen_exact_match": False,
                    "fen_similarity_score": 0.0,
                    "reward_accuracy": 0.0,
                    "flag_accuracy": 0.0
                }
            
            # FEN comparison
            fen_exact = parsed.new_fen == expected_response.new_fen
            fen_similarity = self._compute_fen_similarity(
                parsed.new_fen, expected_response.new_fen
            )
            
            # Reward accuracy (1.0 - normalized absolute error)
            reward_error = abs(parsed.reward - expected_response.reward)
            reward_accuracy = max(0.0, 1.0 - reward_error)
            
            # Flag accuracy (0.5 per correct flag)
            flag_accuracy = 0.0
            if parsed.terminated == expected_response.terminated:
                flag_accuracy += 0.5
            if parsed.truncated == expected_response.truncated:
                flag_accuracy += 0.5
            
            return {
                "is_valid_format": True,
                "parsed_response": parsed,
                "fen_exact_match": fen_exact,
                "fen_similarity_score": fen_similarity,
                "reward_accuracy": reward_accuracy,
                "flag_accuracy": flag_accuracy
            }
            
        except Exception:
            return {
                "is_valid_format": False,
                "parsed_response": None,
                "fen_exact_match": False,
                "fen_similarity_score": 0.0,
                "reward_accuracy": 0.0,
                "flag_accuracy": 0.0
            }
    
    def parse_prediction(self, predicted_text: str) -> Optional[EnvironmentResponse]:
        """
        Parse model's A: task prediction into structured response
        
        Expected format: "A: prev_fen+uci+history+new_fen+reward+terminated+truncated"
        
        Args:
            predicted_text: Raw model output
            
        Returns:
            Parsed EnvironmentResponse or None if parsing fails
        """
        try:
            # Remove A: prefix if present
            text = predicted_text.strip()
            if text.startswith("A: "):
                text = text[3:]
            
            # Split by + delimiter
            parts = text.split('+')
            
            if len(parts) < 7:
                return None
            
            # Parse components
            previous_fen = parts[0].strip()
            uci_move = parts[1].strip()
            move_history = parts[2].strip()
            new_fen = parts[3].strip()
            
            try:
                reward = float(parts[4].strip())
                terminated = bool(int(parts[5].strip()))
                truncated = bool(int(parts[6].strip()))
            except (ValueError, IndexError):
                return None
            
            # Basic validation
            if not previous_fen or not uci_move or not new_fen:
                return None
            
            return EnvironmentResponse(
                previous_fen=previous_fen,
                uci_move=uci_move,
                move_history=move_history,
                new_fen=new_fen,
                reward=reward,
                terminated=terminated,
                truncated=truncated
            )
            
        except Exception:
            return None
    
    def _compute_fen_similarity(self, predicted_fen: str, expected_fen: str) -> float:
        """
        Compute similarity between FEN strings using Levenshtein distance
        
        Args:
            predicted_fen: Predicted FEN string
            expected_fen: Expected FEN string
            
        Returns:
            Similarity score (0.0 to 1.0)
        """
        try:
            from difflib import SequenceMatcher
            
            # Use difflib for similarity calculation
            matcher = SequenceMatcher(None, predicted_fen, expected_fen)
            return matcher.ratio()
            
        except Exception:
            return 0.0
    
    def get_legal_moves(self, fen: str) -> List[str]:
        """
        Get list of legal UCI moves for a position
        
        Args:
            fen: Board position in FEN notation
            
        Returns:
            List of legal UCI move strings
        """
        try:
            board = chess.Board(fen)
            return [move.uci() for move in board.legal_moves]
        except Exception:
            return []
    
    def is_valid_move(self, fen: str, uci_move: str) -> bool:
        """
        Check if a UCI move is legal in the given position
        
        Args:
            fen: Board position in FEN notation  
            uci_move: UCI move string
            
        Returns:
            True if move is legal, False otherwise
        """
        try:
            board = chess.Board(fen)
            move = chess.Move.from_uci(uci_move)
            return move in board.legal_moves
        except Exception:
            return False
    
    def validate_prediction(self, generated_text: str, expected_response: EnvironmentResponse) -> Dict[str, Any]:
        """
        Validate model prediction against expected environment response
        
        Args:
            generated_text: Model's generated output (should be A: format)
            expected_response: Ground truth environment response
            
        Returns:
            Dictionary with validation results
        """
        validation = {
            "is_valid_format": False,
            "fen_exact_match": False,
            "fen_similarity_score": 0.0,
            "reward_accuracy": 0.0,
            "flag_accuracy": 0.0,
            "parsed_response": None
        }
        
        # Try to parse the prediction
        parsed = self.parse_prediction(generated_text)
        if parsed is None:
            return validation
        
        validation["is_valid_format"] = True
        validation["parsed_response"] = parsed
        
        # Check FEN exact match
        validation["fen_exact_match"] = (parsed.new_fen == expected_response.new_fen)
        
        # Calculate FEN similarity
        validation["fen_similarity_score"] = self._compute_fen_similarity(
            parsed.new_fen, expected_response.new_fen
        )
        
        # Calculate reward accuracy (as percentage error)
        try:
            reward_diff = abs(parsed.reward - expected_response.reward)
            max_reward = max(abs(parsed.reward), abs(expected_response.reward), 1.0)
            validation["reward_accuracy"] = 1.0 - min(reward_diff / max_reward, 1.0)
        except:
            validation["reward_accuracy"] = 0.0
        
        # Calculate flag accuracy (both terminated and truncated must match)
        flags_correct = (
            parsed.terminated == expected_response.terminated and
            parsed.truncated == expected_response.truncated
        )
        validation["flag_accuracy"] = 1.0 if flags_correct else 0.0
        
        return validation
    
    def create_sample_positions(self, n_positions: int = 10) -> List[str]:
        """
        Create sample chess positions for testing
        
        Args:
            n_positions: Number of positions to generate
            
        Returns:
            List of FEN position strings
        """
        positions = []
        
        # Start with common opening positions
        opening_positions = [
            "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1",  # Starting position
            "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq e3 0 1",  # e4
            "rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq d3 0 1",  # d4
            "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq e6 0 2",  # e4 e5
            "rnbqkbnr/pp1ppppp/8/2p5/4P3/8/PPPP1PPP/RNBQKBNR w KQkq c6 0 2",  # Sicilian
        ]
        
        positions.extend(opening_positions[:min(n_positions, len(opening_positions))])
        
        # Generate additional positions by playing random moves
        while len(positions) < n_positions:
            try:
                board = chess.Board()
                # Play 5-15 random moves
                import random
                n_moves = random.randint(5, 15)
                
                for _ in range(n_moves):
                    legal_moves = list(board.legal_moves)
                    if not legal_moves:
                        break
                    move = random.choice(legal_moves)
                    board.push(move)
                
                if not board.is_game_over():
                    positions.append(board.fen())
                    
            except Exception:
                continue
        
        return positions[:n_positions]